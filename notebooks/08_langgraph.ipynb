{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e1ec91",
   "metadata": {},
   "source": [
    "## Building a Langgraph Orchesterian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264f93b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\krishisahayi\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from typing import Annotated, Literal, Any,List\n",
    "from pydantic import SecretStr\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96883acd",
   "metadata": {},
   "source": [
    "### Set your Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b0c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9304b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96da0c1",
   "metadata": {},
   "source": [
    "### state function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6cff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    message_types: str | None\n",
    "    question: str | None\n",
    "    context: str | None\n",
    "    rag_chain: Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175adad",
   "metadata": {},
   "source": [
    "## MessageClassifier Node : to get the intent of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88db6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageClassifier(BaseModel):\n",
    "    message_type: Literal[\"agricultural\", \"logical\", \"informational\"] = Field(\n",
    "        ...,\n",
    "        description=\"Classify if the message requires an agricultural, informational, or logical response.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c62331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(state: State):\n",
    "    \"\"\"\n",
    "    Classifies the user's message into one of three categories:\n",
    "    'agricultural', 'informational', or 'logical'.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    user_query = last_message.content\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    Classify the user's message based on its core intent:\n",
    "    - 'agricultural': **Hands-on farming advice.** Questions about crop care, soil, pests, diseases, or agricultural techniques.\n",
    "    - 'informational': **Factual data retrieval.** Queries about government schemes, market prices, or content from documents/websites.\n",
    "    - 'logical': **General knowledge/reasoning.** Simple questions, calculations, or topics unrelated to farming.\n",
    "    Provide only one of the three category names as your output.\n",
    "    \"\"\"\n",
    "    classifier_llm = llm.with_structured_output(MessageClassifier)\n",
    "    try:\n",
    "        result = classifier_llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ])\n",
    "        message_type = result.message_type #type: ignore\n",
    "        return {\"message_types\": message_type, \"question\": user_query}\n",
    "    except Exception as e:\n",
    "        return {\"message_types\": \"logical\", \"question\": user_query}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9999ad6",
   "metadata": {},
   "source": [
    "## Router Node to point to the right next Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7a7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: State):\n",
    "    message_type = state.get(\"message_types\")\n",
    "    \n",
    "    if message_type == \"informational\":\n",
    "        return {\"next\": \"informational_rag_node\"}\n",
    "    elif message_type == \"agricultural\":\n",
    "        return {\"next\": \"agricultural\"}\n",
    "    else:\n",
    "        return {\"next\": \"logical\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586d45a",
   "metadata": {},
   "source": [
    "## RAG chain Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf66be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_rag_chain(state: State):\n",
    "    rag_chain = state[\"rag_chain\"]\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Correctly access the content of a LangChain message object\n",
    "    user_query = last_message.content\n",
    "    \n",
    "    response = rag_chain.invoke({\"input\": user_query})\n",
    "    answer = response.get(\"answer\", \"I'm not sure. Please rephrase or upload a document.\")\n",
    "    \n",
    "    return {\"messages\": [AIMessage(content=answer)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0534b",
   "metadata": {},
   "source": [
    "## Agricultural agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8e3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agricultural_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    user_query = last_message.content\n",
    "    \n",
    "    context = state.get(\"context\", \"\")\n",
    "    question = state.get(\"question\", user_query)\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    You are a sustainable farming expert and an ecological guide.\n",
    "    **Instructions:**\n",
    "    1.  Use the following `Context` to answer the `Question`.\n",
    "    2.  If the context is insufficient, provide a solution based on your general knowledge.\n",
    "    3.  Your advice must promote soil health, integrated pest management (IPM), and water conservation.\n",
    "    4.  Encourage long-term sustainability and a holistic view of the farm ecosystem.\n",
    "    **Context:** {context}\n",
    "    **Question:** {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        reply = llm.invoke(messages)\n",
    "        return {\"messages\": [AIMessage(content=reply.content)]}\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [AIMessage(content=\"I'm sorry, an error occurred while processing your request. Please try again.\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae2a72",
   "metadata": {},
   "source": [
    "## Logical agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9faf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    user_query = last_message.content\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"You are a Logical Replier. Your only function is to provide a structured, reasoned response to any query.\n",
    "        question:{user_query}.\n",
    "        Your process:\n",
    "        Deconstruct: Identify the core parts of the user's query.\n",
    "        Analyze: Use step-by-step logic to process the information.\n",
    "        Conclude: Provide a direct, factual conclusion based on your analysis.\n",
    "        Be concise, objective, and use a structured format (e.g., numbered lists). Avoid conversational fillers, opinions, or unnecessary details.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        reply = llm.invoke(messages)\n",
    "        return {\"messages\": [AIMessage(content=reply.content)]}\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [AIMessage(content=\"I'm sorry, an error occurred while processing your request. Please try again.\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8327bf",
   "metadata": {},
   "source": [
    "## Informational Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ad37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def informational_agent(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    user_query = last_message.content\n",
    "    context = state.get(\"context\", \"\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"\n",
    "        question:{user_query}\n",
    "        context:{context}\n",
    "        You are a rag agent you have certain pdf and data around the informational farming schemes by government and crop knowledge with\n",
    "        disease detection and cure recommendation with keeping the cure as envirometnal friendly and healthy for soil and seasonal crops.\n",
    "        Your job will be to evaluate the answers with all the informational context. \n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        reply = llm.invoke(messages)\n",
    "        return {\"messages\": [AIMessage(content=reply.content)]}\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [AIMessage(content=\"I'm sorry, an error occurred while processing your request. Please try again.\")]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df7cd8",
   "metadata": {},
   "source": [
    "## Create Graph Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a851a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    graph_builder = StateGraph(State)\n",
    "    graph_builder.add_node(\"classifier\", classify_message)\n",
    "    graph_builder.add_node(\"router\", router)\n",
    "    graph_builder.add_node(\"informational_rag_node\", call_rag_chain)\n",
    "    graph_builder.add_node(\"agricultural\", agricultural_agent)\n",
    "    graph_builder.add_node(\"logical\", logical_agent)\n",
    "\n",
    "    graph_builder.add_edge(START, \"classifier\")\n",
    "    graph_builder.add_edge(\"classifier\", \"router\")\n",
    "    \n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda state: state.get(\"next\"),\n",
    "        {\n",
    "            \"agricultural\": \"agricultural\",\n",
    "            \"informational_rag_node\": \"informational_rag_node\",\n",
    "            \"logical\": \"logical\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    graph_builder.add_edge(\"agricultural\", END)\n",
    "    graph_builder.add_edge(\"informational_rag_node\", END)\n",
    "    graph_builder.add_edge(\"logical\", END)\n",
    "\n",
    "    graph = graph_builder.compile()\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2366416",
   "metadata": {},
   "source": [
    "## display graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FINAL GUARANTEE! Graph structure saved as text file: agri_bot_flow.mermaid\n",
      "Copy the contents of this file and paste it into mermaid.live to get your PNG image.\n"
     ]
    }
   ],
   "source": [
    "# 1. Compile the graph\n",
    "app_graph = create_graph()\n",
    "\n",
    "# 2. Get the raw Mermaid source string\n",
    "mermaid_code = app_graph.get_graph().draw_mermaid()\n",
    "\n",
    "# 3. Save the raw text file\n",
    "dot_file_path = \"agri_bot_flow.mermaid\"\n",
    "with open(dot_file_path, \"w\") as f:\n",
    "    f.write(mermaid_code)\n",
    "\n",
    "print(f\"✅Graph structure saved as text file: {dot_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
